{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Скачать библиотеки и инициализировать device"
      ],
      "metadata": {
        "id": "XdURq0prgWST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from typing import Dict, Tuple"
      ],
      "metadata": {
        "id": "IN7iobfnrh2S"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO-sD81RgoHB",
        "outputId": "99836256-1e48-44a5-9eb8-096ea8bb7404"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Датасет"
      ],
      "metadata": {
        "id": "64KZguDRSazx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASjydXERrglv",
        "outputId": "3685ec95-cf3f-4d28-f755-4751ef3558b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=139GsP9CqFCW1LA1Mf3e1gZpWz2uXmfHf\n",
            "To: /content/datasets/tiny-floodnet-challenge.tar.gz\n",
            "100% 50.4M/50.4M [00:01<00:00, 34.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir datasets\n",
        "!gdown --id 139GsP9CqFCW1LA1Mf3e1gZpWz2uXmfHf -O datasets/tiny-floodnet-challenge.tar.gz\n",
        "!tar -xzf datasets/tiny-floodnet-challenge.tar.gz -C datasets\n",
        "!rm datasets/tiny-floodnet-challenge.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FloodNet(Dataset):\n",
        "\n",
        "    def __init__(self, data_path: str, phase: str, augment: bool, img_size: int):\n",
        "        self.num_classes = 8\n",
        "        self.data_path = data_path\n",
        "        self.phase = phase\n",
        "        self.augment = augment\n",
        "        self.img_size = img_size\n",
        "        self.items = [filename.split('.')[0] for filename in os.listdir(f'{data_path}/{phase}/image')]\n",
        "        if augment:\n",
        "          self.transform = A.Compose([\n",
        "                                      A.RandomScale(), \n",
        "                                      A.RandomCrop(width=self.img_size, height=self.img_size),\n",
        "                                      A.Rotate(limit=30),\n",
        "                                      A.Flip(p=0.5),\n",
        "                                      A.HueSaturationValue()])\n",
        "        else:\n",
        "          self.transform = A.RandomCrop(width=self.img_size, height=self.img_size)\n",
        "        self.to_tensor = ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = np.asarray(Image.open(f'{self.data_path}/{self.phase}/image/{self.items[index]}.jpg'))\n",
        "        if self.phase == 'train':\n",
        "          transformed = self.transform(image=image)\n",
        "          image = transformed['image']\n",
        "        image = self.to_tensor(image.copy())\n",
        "        if self.phase == 'train':\n",
        "          assert isinstance(image, torch.FloatTensor) and image.shape == (3, self.img_size, self.img_size)\n",
        "        return image"
      ],
      "metadata": {
        "id": "lFz8MLmdrkZ-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = FloodNet(data_path = 'datasets/tiny-floodnet-challenge',\n",
        "                   phase = 'train',\n",
        "                   augment = True,\n",
        "                   img_size = 64)\n",
        "\n",
        "loader = DataLoader(dataset, \n",
        "                    num_workers = 8,\n",
        "                    batch_size = 32 , \n",
        "                    shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A67FddzutqfL",
        "outputId": "3270eded-4341-4e66-e127-977228a2867f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check \n",
        "for data in loader:\n",
        "  print(data.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBlK94l0enXe",
        "outputId": "3ffd24a3-9ac4-4446-b566-600ebf9ff1b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "MZPDF7LzlGwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DDPM(nn.Module):\n",
        "  def __init__(self, eps_model: nn.Module, betas: Tuple[float, float], n_T: int, criterion: nn.Module = nn.MSELoss()) -> None:\n",
        "    super(DDPM, self).__init__()\n",
        "    self.eps_model = eps_model\n",
        "\n",
        "    # register_buffer allows us to freely access these tensors by name. It helps device placement.\n",
        "    for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
        "        self.register_buffer(k, v)\n",
        "\n",
        "    self.n_T = n_T\n",
        "    self.criterion = criterion\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Makes forward diffusion x_t, and tries to guess epsilon value from x_t using eps_model.\n",
        "    This implements Algorithm 1 in the paper.\n",
        "    \"\"\"\n",
        "\n",
        "    _ts = torch.randint(1, self.n_T + 1, (x.shape[0],)).to(x.device)\n",
        "    # t ~ Uniform(0, n_T)\n",
        "    eps = torch.randn_like(x)  # eps ~ N(0, 1)\n",
        "\n",
        "    x_t = (\n",
        "        self.sqrtab[_ts, None, None, None] * x\n",
        "        + self.sqrtmab[_ts, None, None, None] * eps\n",
        "    )  # This is the x_t, which is sqrt(alphabar) x_0 + sqrt(1-alphabar) * eps\n",
        "    # We should predict the \"error term\" from this x_t. Loss is what we return.\n",
        "\n",
        "    return self.criterion(eps, self.eps_model(x_t, _ts / self.n_T))\n",
        "\n",
        "  def sample(self, n_sample: int, size, device) -> torch.Tensor:\n",
        "\n",
        "    x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1)\n",
        "\n",
        "    # This samples accordingly to Algorithm 2. It is exactly the same logic.\n",
        "    for i in range(self.n_T, 0, -1):\n",
        "      z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
        "      eps = self.eps_model(x_i, torch.tensor(i / self.n_T).to(device).repeat(n_sample, 1))\n",
        "      x_i = (self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i]) + self.sqrt_beta_t[i] * z)\n",
        "\n",
        "    return x_i\n",
        "\n",
        "\n",
        "def ddpm_schedules(beta1: float, beta2: float, T: int) -> Dict[str, torch.Tensor]:\n",
        "  \"\"\"\n",
        "  Returns pre-computed schedules for DDPM sampling, training process.\n",
        "  \"\"\"\n",
        "  assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
        "\n",
        "  beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
        "  sqrt_beta_t = torch.sqrt(beta_t)\n",
        "  alpha_t = 1 - beta_t\n",
        "  log_alpha_t = torch.log(alpha_t)\n",
        "  alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
        "\n",
        "  sqrtab = torch.sqrt(alphabar_t)\n",
        "  oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
        "\n",
        "  sqrtmab = torch.sqrt(1 - alphabar_t)\n",
        "  mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
        "\n",
        "  return {\n",
        "    \"alpha_t\": alpha_t,  # \\alpha_t\n",
        "    \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
        "    \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
        "    \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
        "    \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
        "    \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
        "    \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
        "  }"
      ],
      "metadata": {
        "id": "FbJMCb5WtrAL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv3(nn.Module):\n",
        "  def __init__(\n",
        "    self, in_channels: int, out_channels: int, is_res: bool = False) -> None:\n",
        "    super().__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "      nn.GroupNorm(8, out_channels),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "      nn.GroupNorm(8, out_channels),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "      nn.GroupNorm(8, out_channels),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.is_res = is_res\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = self.main(x)\n",
        "    if self.is_res:\n",
        "      x = x + self.conv(x)\n",
        "      return x / 1.414\n",
        "    else:\n",
        "      return self.conv(x)\n",
        "\n",
        "\n",
        "class UnetDown(nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "    super(UnetDown, self).__init__()\n",
        "    layers = [Conv3(in_channels, out_channels), nn.MaxPool2d(2)]\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "    return self.model(x)\n",
        "\n",
        "\n",
        "class UnetUp(nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "    super(UnetUp, self).__init__()\n",
        "    layers = [\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n",
        "        Conv3(out_channels, out_channels),\n",
        "        Conv3(out_channels, out_channels),\n",
        "    ]\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, skip: torch.Tensor) -> torch.Tensor:\n",
        "    x = torch.cat((x, skip), 1)\n",
        "    x = self.model(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class TimeSiren(nn.Module):\n",
        "  def __init__(self, emb_dim: int) -> None:\n",
        "    super(TimeSiren, self).__init__()\n",
        "\n",
        "    self.lin1 = nn.Linear(1, emb_dim, bias=False)\n",
        "    self.lin2 = nn.Linear(emb_dim, emb_dim)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = x.view(-1, 1)\n",
        "    x = torch.sin(self.lin1(x))\n",
        "    x = self.lin2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "YHI3k4Bxl5ab"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveUnet(nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int, n_feat: int = 256) -> None:\n",
        "    super(NaiveUnet, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "    self.n_feat = n_feat\n",
        "\n",
        "    self.init_conv = Conv3(in_channels, n_feat, is_res=True)\n",
        "\n",
        "    self.down1 = UnetDown(n_feat, n_feat)\n",
        "    self.down2 = UnetDown(n_feat, 2 * n_feat)\n",
        "    self.down3 = UnetDown(2 * n_feat, 2 * n_feat)\n",
        "\n",
        "    self.to_vec = nn.Sequential(nn.AvgPool2d(4), nn.ReLU())\n",
        "\n",
        "    self.timeembed = TimeSiren(2 * n_feat)\n",
        "\n",
        "    self.up0 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, 4, 4),\n",
        "        nn.GroupNorm(8, 2 * n_feat),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.up1 = UnetUp(4 * n_feat, 2 * n_feat)\n",
        "    self.up2 = UnetUp(4 * n_feat, n_feat)\n",
        "    self.up3 = UnetUp(2 * n_feat, n_feat)\n",
        "    self.out = nn.Conv2d(2 * n_feat, self.out_channels, 3, 1, 1)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "    x = self.init_conv(x)\n",
        "\n",
        "    down1 = self.down1(x)\n",
        "    down2 = self.down2(down1)\n",
        "    down3 = self.down3(down2)\n",
        "\n",
        "    thro = self.to_vec(down3)\n",
        "    temb = self.timeembed(t).view(-1, self.n_feat * 2, 1, 1)\n",
        "\n",
        "    thro = self.up0(thro + temb)\n",
        "\n",
        "    up1 = self.up1(thro, down3) + temb\n",
        "    up2 = self.up2(up1, down2)\n",
        "    up3 = self.up3(up2, down1)\n",
        "\n",
        "    out = self.out(torch.cat((up3, x), 1))\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "JwiKK6TllmKl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DDPM(eps_model=NaiveUnet(3, 3, n_feat=128), betas=(1e-4, 0.02), n_T=1000).to(device)"
      ],
      "metadata": {
        "id": "SfP2oFx2trH2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train\n"
      ],
      "metadata": {
        "id": "O1VqWJ89gP4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 3e-4\n",
        "num_epochs = 10\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "ADe-rUY4gPBs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "  model.train()\n",
        "  for idx, data in enumerate(loader):\n",
        "    data = data.to(device)\n",
        "    optim.zero_grad()\n",
        "    loss = model(data)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    xh = model.sample(8, (3, 128, 128), device)\n",
        "    xset = torch.cat([xh, data[:8]], dim=0)\n",
        "    grid = make_grid(xset, normalize=True, value_range=(-1, 1), nrow=4)\n",
        "    save_image(grid, f\"./contents/model_sample{i:03d}.png\")\n",
        "\n",
        "    # save model\n",
        "    torch.save(model.state_dict(), f\"./model_floodnet.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "fhIRXgFeg3O8",
        "outputId": "c263338a-94e4-44ec-d9d4-df8ead622415"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f216f9c1ed2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mxh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mxset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8834dc5673d8>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n_sample, size, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# This samples accordingly to Algorithm 2. It is exactly the same logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moneover_sqrta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmab_over_sqrtmab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_beta_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5upAgDeLg3dZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}